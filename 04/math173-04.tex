\documentclass{../homework}

\homework{4}
\date{Tuesday 2/19}

\author{}
\coauthor{}

\begin{document}
\begin{description}
\item[P.6.25] Let \(A \in \M_n\) and let \(A = QR\) be a \(QR\)
  factorization.  Let
  \(
  A =
  \begin{bmatrix}
    \vec a_1 & \vec a_2 & \dots & \vec a_n
  \end{bmatrix}
  \),
  \(
  Q =
  \begin{bmatrix}
    \vec q_1 & \vec q_2 & \dots & \vec q_n
  \end{bmatrix}
  \),
  and
  \(
  R =
  \begin{bmatrix}
    \vec r_1 & \vec r_2 & \dots \vec r_n
  \end{bmatrix}
  =
  \begin{bmatrix} r_{ij} \end{bmatrix}
  \).
  \begin{enumerate}
  \item Explain why
    \(\abs{\det A} = \det R = r_{11} r_{22} \dots r_{nn}\).

    \begin{solution}

    \end{solution}

  \item Show that \(\norm{\vec a_i}_2 = \norm{\vec r_i}_2 \ge r_{ii}\)
    for each \(i = 1, 2, \dots, n\), with equality for some \(i\) if
    and only if \(\vec a_i = r_{ii} \vec q_i\).

    \begin{solution}
      \begin{proof}

      \end{proof}
    \end{solution}

  \item Conclude that
    \[
      \abs{\det A} \le \norm{\vec a_1}_2 \norm{\vec a_2}_2
      \dots \norm{\vec a_n}_2
      \tag{6.7.2}
    \]
    with equality if and only if either \(A\) has a zero column or
    \(A\) has orthogonal columns (that is,
    \(A^* A = \diag (\norm{\vec a_1}_2^2, \norm{\vec a_2}_2^2, \dots,
    \norm{\vec a_n}_2^2)\)).  This is \textit{Hadamard's Inequality}.

    \begin{solution}
      \begin{proof}

      \end{proof}
    \end{solution}
  \end{enumerate}

\item[P.6.36] Prove that a square matrix is similar to an upper
  triangular matrix if and only if it is unitarily similar to some
  upper triangular matrix.  Hint: If \(A = SBS^{-1}\), consider the
  \(QR\) factorization of \(S\).

  \begin{solution}
    \begin{proof}

    \end{proof}
  \end{solution}

\item[P.6.43] If \(U \in \M_m\) and \(V \in \M_n\) are unitary, show
  that \(U \otimes V \in \M_{mn}\) is unitary.

  \begin{solution}
    \begin{proof}

    \end{proof}
  \end{solution}

\item[P.7.1] Consider
  \[
    A_1 =
    \begin{bmatrix}
      1 & 0 \\
      0 & 0
    \end{bmatrix},
    \quad
    A_2 =
    \begin{bmatrix}
      \frac 1 2 & \frac 1 2 \\
      \frac 1 2 & \frac 1 2
    \end{bmatrix},
    \quad \text{and} \quad
    A_3 =
    \begin{bmatrix}
      1 & 1 \\
      0 & 0
    \end{bmatrix}.
  \]
  \begin{enumerate}
  \item Verify that \(A_1, A_2, A_3\) are idempotent.  Draw a diagram
    illustrating \(\nullspace A_i\) for \(i = 1, 2, 3\).

    \begin{solution}

    \end{solution}

  \item
    \label{part:which-orthogonal-projections}
    Which, if any, of \(A_1, A_2, A_3\) are orthogonal
    projections?

    \begin{solution}

    \end{solution}

  \item Verify that the method of Example 7.3.5 produces the
    orthogonal projections found in
    \ref{part:which-orthogonal-projections}.

    \begin{bookexample}[7.3.5]
      Suppose that \(\vec u_1, \vec u_2, \dots, \vec u_r\) is an
      orthonormal basis for a subspace \(\Uspace\) of \(\FF^n\) and
      let \(\Uspace =
      \begin{bmatrix}
        \vec u_1 & \vec u_2 & \dots \vec u_r
      \end{bmatrix}
      \in \M_{n \times r}\).  For any \(\vec v \in \FF^n\),
      \begin{align*}
        \begin{split}
          P_\Uspace \vec v
          &= \sum_{i=1}^r \inner{\vec v, \vec u_i} \vec u_i
          = \sum_{i=1}^r \vec u_i (\vec u_i^* \vec v)
          = \sum_{i=1}^r (\vec u_i \vec u_i^*) \vec v \\
          &= \Paren{\sum_{i=1}^r \vec u_i \vec u_i^*} \vec v
          = U U^* \vec v,
        \end{split}
        \tag{7.3.6}
      \end{align*}
      in which we invoke (3.1.19) for the final equality.  For
      example, if \(A \in \M_{m \times n} (\FF)\) has full column rank
      and \(A = QR\) is a \(QR\) factorization, then
      \(\col A = \col Q\) (Corollary 6.5.15).  Therefore,
      \[
        P_{\col A} = Q Q^*
        \tag{7.3.7}
      \]
      is the orthogonal projection onto the column space of \(A\).
    \end{bookexample}

    \begin{book}
      \[
        AB =
        \begin{bmatrix}
          \vec a_1 & \vec a_2 & \dots & \vec a_r
        \end{bmatrix}
        \begin{bmatrix}
          \vec b_1^\transpose \\ \dots \\ \vec b_r^\transpose
        \end{bmatrix}
        = \vec a_1 \vec b_1^\transpose
        + \vec a_2 \vec b_2^\transpose
        + \dots
        + \vec a_r \vec b_r^\transpose
        \tag{3.1.19}
      \]
    \end{book}

    \begin{bookcorollary}[6.5.15]
      Let \(A \in \M_{m \times n} (\FF)\).  Suppsoe that \(m \ge n\)
      and \(\rank A = n\).  Let \(A = QR\), in which
      \(Q \in \M_{m \times n} (\FF)\) has orthonormal columns and
      \(R \in \M_n (\FF)\) is upper triangular and has positive
      diagonal entries.  For each \(k = 1, 2, \dots, n\), let \(A_k\)
      and \(Q_k\) denote the submatrices of \(A\) and \(Q\),
      respectively, comprising their first \(k\) columns.  Then
      \[
        \col A_k = \col Q_k, \quad k = 1, 2, \dots, n,
      \]
      that is, the columns of each submatrix \(Q_k\) are an
      orthonormal basis for \(\col A_k\).
    \end{bookcorollary}

    \begin{solution}

    \end{solution}
  \end{enumerate}

\item[P.7.2] If \(A \in \M_n\), show that
  \[
    M =
    \begin{bmatrix}
      A   & A \\
      I-A & I-A
    \end{bmatrix}
  \]
  is idempotent.  When is \(M\) an orthogonal projection?

\item[P.7.6] Let
  \(\vec u = \begin{bmatrix} a & b & c \end{bmatrix}^\transpose \in
  \RR^3\) be a unit vector and let \(U\) denote the plane in \(\RR^3\)
  defined by the equation \(a x_1 + b x_2 + c x_3 = 0\).  Find the
  explicit \(3 \times 3\) matrix \(P\) that represents, with respect
  to the standard basis of \(\RR^3\), the orthogonal projection from
  \(\RR^3\) onto \(U\).  Verify that \(P \vec u = \vec 0\) and that
  \(P\) is Hermitian and idempotent.

  \begin{solution}

  \end{solution}

\item[P.7.9] Let
  \[
    A =
    \begin{bmatrix}
      1 & 2 & 1 \\
      2 & 4 & 2 \\
      0 & 1 & 0
    \end{bmatrix}
    \quad \text{and} \quad
    \vec y =
    \begin{bmatrix}
      1 \\ 2 \\ 1
    \end{bmatrix}.
  \]
  Show that \(A \vec x = \vec y\) is consistent and show that
  \[
    \vec s =
    \begin{bmatrix}
      -\frac 1 2 & 1 & -\frac 1 2
    \end{bmatrix}^\transpose
  \]
  is its minimum norm solution.

  \begin{solution}

  \end{solution}

\item[P.7.10] Suppose that \(A \in \M_{m \times n}\) has full row rank
  and let \(A^* = QR\) be a narrow \(QR\) factorization.  Show that
  the minimum norm solution of \(A \vec x = \vec y\) is
  \(\vec x = Q{R^-}^* \vec y\).

  \begin{solution}
    \begin{proof}

    \end{proof}
  \end{solution}
\end{description}
\end{document}